### 在线算法 - 海量数据处理算法

#### 外排序 External Sorting
- 特点:
    - 通常处理大数据，当内存不够时如何对多个大型数据进行排序
    - Batch Processing 避免单一文件OOM
    - 每一个batch加入一个缓存Buffer依次用来缓存一定量的输入输出，避免一个个输入输出这种效率低下的方法

- 基本步骤
    1. 将大文件划分成若干个块，并分别使用内存排序
    2. 使用K路归并算法将若干排好序的小文件进行合并成大文件

第一步：文件拆分
    根据内存的大小，尽可能多的分批次的将数据 Load 到内存中，并使用系统自带的内存排序函数（或者自己写个快速排序算法），
    将其排好序，并输出到一个个小文件中。比如一个文件有1T，内存有1G，那么我们就这个大文件中的内容按照 1G 的大小，分批次的导入内存，排序之后输出得到 1024 个 1G 的小文件。

第二步：K路归并算法
    K路归并算法使用的是数据结构堆（Heap）来完成的，使用 Java 或者 C++ 的同学可以直接用语言自带的 PriorityQueue（C++中叫priority_queue）来代替。
    我们将 K 个文件中的第一个元素加入到堆里，假设数据是从小到大排序的话，那么这个堆是一个最小堆（Min Heap）。
    每次从堆中选出最小的元素，输出到目标结果文件中，然后如果这个元素来自第 x 个文件，
    则从第 x 个文件中继续读入一个新的数进来放到堆里，并重复上述操作，直到所有元素都被输出到目标结果文件中。

Follow up: 一个个从文件中读入数据，一个个输出到目标文件中操作很慢，如何优化？
    如果我们每个文件只读入1个元素并放入堆里的话，总共只用到了 1024 个元素，这很小，没有充分的利用好内存。
    另外，单个读入和单个输出的方式也不是磁盘的高效使用方式。因此我们可以为输入和输出都分别加入一个缓冲（Buffer）。
    假如一个元素有10个字节大小的话，1024 个元素一共 10K，1G的内存可以支持约 100K 组这样的数据，那么我们就为每个文件设置一个 100K 大小的 Buffer， 每次需要从某个文件中读数据，都将这个 Buffer 装满。
    当然 Buffer 中的数据都用完的时候，再批量的从文件中读入。输出同理，设置一个 Buffer 来避免单个输出带来的效率缓慢。
    那下面我们就来熟悉下两路归并和K路归并的算法。

### 归并排序的衍生用法
#### 数组合并
- 多个intervel数组进行合并
    - n个区间 [l1, r1], [l2, r2], ... , [ln, rn] -> 按包含关心进行合并
    
#### 数组交集
- 将两个数组交集找出
    - HashSet - Time:O(N), Space: O(N)
    - Sort + Binary Search - Time: O(NlogN), Space: O(1)
    
#### 稀疏矩阵
- 稀疏矩阵找交集只在交集处计算

